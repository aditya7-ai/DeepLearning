{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd   #loading and handling dataset\n",
        "import numpy as np    #for numerical operations\n",
        "import tensorflow as tf   #building and training neural networks\n",
        "from sklearn.model_selection import train_test_split  #To split data into training and testing sets\n",
        "from sklearn.preprocessing import StandardScaler      #To normalize/scale features\n",
        "from sklearn.metrics import classification_report, confusion_matrix    #For evaluation metrics\n",
        "from sklearn.preprocessing import LabelEncoder     #To convert labels into numbers"
      ],
      "metadata": {
        "id": "-OKyhTkGQ-Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"wine.csv\")  # Load the CSV file\n",
        "print(df['quality'].value_counts())      # Check how many examples are present for each quality score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHnGjGPsRAlt",
        "outputId": "53ebed80-1623-427d-de21-22231690dfec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quality\n",
            "5    681\n",
            "6    638\n",
            "7    199\n",
            "4     53\n",
            "8     18\n",
            "3     10\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(\"quality\", axis=1)  # X contains all columns except the target column \"quality\"\n",
        "y = df[\"quality\"]               # y contains only the \"quality\" column, which is our label\n",
        "\n",
        "# Encode labels from [3–8] to [0–5] for softmax\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# One-hot encode target\n",
        "y_onehot = tf.keras.utils.to_categorical(y_encoded)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_onehot, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "t0ZoJHxIRCDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([                     # Create a sequential model (one layer after another)\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer with 128 neurons\n",
        "    tf.keras.layers.Dropout(0.3),                        # Dropout layer to avoid overfitting (randomly drops 30% neurons)\n",
        "    tf.keras.layers.Dense(64, activation='relu'),        # Hidden layer with 64 neurons and ReLU activation\n",
        "    tf.keras.layers.Dropout(0.3),                        # Another dropout layer\n",
        "    tf.keras.layers.Dense(6, activation='softmax')       # Output layer with 6 neurons (for 6 classes) and softmax\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AdQj3zqRGuA",
        "outputId": "8cf6fc0d-f581-4f3d-e1b0-5a6dad23ddf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',                     # Adam optimizer automatically adjusts learning rate\n",
        "    loss='categorical_crossentropy',      # Loss function for multiclass classification\n",
        "    metrics=['accuracy']                  # Track accuracy while training\n",
        ")\n",
        "\n",
        "model.summary()                           # Print the summary of the model architecture\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "FPBmo6fsSkab",
        "outputId": "0df933b0-aafd-478f-b4c6-84a72c97f61c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,536\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m390\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,182\u001b[0m (39.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,182</span> (39.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,182\u001b[0m (39.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,182</span> (39.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=10,                          # If validation accuracy doesn't improve for 10 epochs, stop training\n",
        "    restore_best_weights=True            # Restore weights from the best-performing epoch\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,                    # Training data\n",
        "    epochs=100,                          # Train for 100 epochs (max)\n",
        "    batch_size=32,                       # Use 32 samples per batch\n",
        "    validation_data=(X_test, y_test),    # Evaluate model on test data after each epoch\n",
        "    callbacks=[early_stop]               # Use early stopping to avoid overfitting\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUHeInqnRIDg",
        "outputId": "b0ff4602-6604-4837-daaf-6fbb43c05d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2970 - loss: 1.6912 - val_accuracy: 0.5219 - val_loss: 1.1929\n",
            "Epoch 2/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5485 - loss: 1.1520 - val_accuracy: 0.5688 - val_loss: 1.0525\n",
            "Epoch 3/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5821 - loss: 1.0579 - val_accuracy: 0.5500 - val_loss: 1.0099\n",
            "Epoch 4/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5971 - loss: 1.0147 - val_accuracy: 0.5312 - val_loss: 0.9893\n",
            "Epoch 5/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6062 - loss: 0.9938 - val_accuracy: 0.5437 - val_loss: 0.9813\n",
            "Epoch 6/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5910 - loss: 0.9823 - val_accuracy: 0.5562 - val_loss: 0.9642\n",
            "Epoch 7/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6316 - loss: 0.9378 - val_accuracy: 0.5531 - val_loss: 0.9506\n",
            "Epoch 8/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5807 - loss: 0.9993 - val_accuracy: 0.5500 - val_loss: 0.9504\n",
            "Epoch 9/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5726 - loss: 1.0060 - val_accuracy: 0.5719 - val_loss: 0.9434\n",
            "Epoch 10/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5899 - loss: 0.9779 - val_accuracy: 0.5500 - val_loss: 0.9404\n",
            "Epoch 11/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6074 - loss: 0.9554 - val_accuracy: 0.5594 - val_loss: 0.9331\n",
            "Epoch 12/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6076 - loss: 0.9594 - val_accuracy: 0.5594 - val_loss: 0.9270\n",
            "Epoch 13/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6354 - loss: 0.9260 - val_accuracy: 0.5625 - val_loss: 0.9221\n",
            "Epoch 14/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6210 - loss: 0.9280 - val_accuracy: 0.5625 - val_loss: 0.9175\n",
            "Epoch 15/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6084 - loss: 0.9108 - val_accuracy: 0.5719 - val_loss: 0.9124\n",
            "Epoch 16/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6364 - loss: 0.8976 - val_accuracy: 0.5562 - val_loss: 0.9087\n",
            "Epoch 17/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6432 - loss: 0.9169 - val_accuracy: 0.5750 - val_loss: 0.9061\n",
            "Epoch 18/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6102 - loss: 0.9216 - val_accuracy: 0.5719 - val_loss: 0.9074\n",
            "Epoch 19/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6188 - loss: 0.9325 - val_accuracy: 0.5719 - val_loss: 0.9028\n",
            "Epoch 20/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6229 - loss: 0.8967 - val_accuracy: 0.5750 - val_loss: 0.9021\n",
            "Epoch 21/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6587 - loss: 0.8651 - val_accuracy: 0.5813 - val_loss: 0.8988\n",
            "Epoch 22/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6239 - loss: 0.8840 - val_accuracy: 0.5781 - val_loss: 0.8954\n",
            "Epoch 23/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6006 - loss: 0.9533 - val_accuracy: 0.5531 - val_loss: 0.8924\n",
            "Epoch 24/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6578 - loss: 0.8810 - val_accuracy: 0.5625 - val_loss: 0.8901\n",
            "Epoch 25/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6255 - loss: 0.9157 - val_accuracy: 0.5969 - val_loss: 0.8912\n",
            "Epoch 26/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6186 - loss: 0.8715 - val_accuracy: 0.5688 - val_loss: 0.8888\n",
            "Epoch 27/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6332 - loss: 0.9056 - val_accuracy: 0.5656 - val_loss: 0.8836\n",
            "Epoch 28/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6042 - loss: 0.8835 - val_accuracy: 0.5875 - val_loss: 0.8837\n",
            "Epoch 29/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6448 - loss: 0.8820 - val_accuracy: 0.5875 - val_loss: 0.8826\n",
            "Epoch 30/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6373 - loss: 0.8792 - val_accuracy: 0.5844 - val_loss: 0.8779\n",
            "Epoch 31/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6425 - loss: 0.8624 - val_accuracy: 0.5750 - val_loss: 0.8772\n",
            "Epoch 32/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6196 - loss: 0.8774 - val_accuracy: 0.5875 - val_loss: 0.8755\n",
            "Epoch 33/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6608 - loss: 0.8607 - val_accuracy: 0.5781 - val_loss: 0.8738\n",
            "Epoch 34/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6300 - loss: 0.8824 - val_accuracy: 0.5875 - val_loss: 0.8756\n",
            "Epoch 35/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6415 - loss: 0.8529 - val_accuracy: 0.5906 - val_loss: 0.8740\n",
            "Epoch 36/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6358 - loss: 0.8504 - val_accuracy: 0.5875 - val_loss: 0.8754\n",
            "Epoch 37/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6492 - loss: 0.8561 - val_accuracy: 0.5813 - val_loss: 0.8747\n",
            "Epoch 38/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6382 - loss: 0.8643 - val_accuracy: 0.5938 - val_loss: 0.8753\n",
            "Epoch 39/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6513 - loss: 0.8800 - val_accuracy: 0.6031 - val_loss: 0.8729\n",
            "Epoch 40/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6633 - loss: 0.8505 - val_accuracy: 0.6000 - val_loss: 0.8737\n",
            "Epoch 41/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6437 - loss: 0.8811 - val_accuracy: 0.5969 - val_loss: 0.8755\n",
            "Epoch 42/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6265 - loss: 0.8513 - val_accuracy: 0.5875 - val_loss: 0.8743\n",
            "Epoch 43/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6233 - loss: 0.8549 - val_accuracy: 0.5969 - val_loss: 0.8730\n",
            "Epoch 44/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6540 - loss: 0.8535 - val_accuracy: 0.5938 - val_loss: 0.8717\n",
            "Epoch 45/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6473 - loss: 0.8454 - val_accuracy: 0.5875 - val_loss: 0.8720\n",
            "Epoch 46/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6765 - loss: 0.7738 - val_accuracy: 0.5969 - val_loss: 0.8761\n",
            "Epoch 47/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6454 - loss: 0.8679 - val_accuracy: 0.5938 - val_loss: 0.8728\n",
            "Epoch 48/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6595 - loss: 0.8391 - val_accuracy: 0.6000 - val_loss: 0.8714\n",
            "Epoch 49/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6667 - loss: 0.8089 - val_accuracy: 0.6031 - val_loss: 0.8673\n",
            "Epoch 50/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6539 - loss: 0.8245 - val_accuracy: 0.5969 - val_loss: 0.8713\n",
            "Epoch 51/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6620 - loss: 0.8286 - val_accuracy: 0.5969 - val_loss: 0.8710\n",
            "Epoch 52/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6588 - loss: 0.8199 - val_accuracy: 0.5906 - val_loss: 0.8720\n",
            "Epoch 53/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6340 - loss: 0.8260 - val_accuracy: 0.5938 - val_loss: 0.8596\n",
            "Epoch 54/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6569 - loss: 0.8348 - val_accuracy: 0.5969 - val_loss: 0.8587\n",
            "Epoch 55/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6479 - loss: 0.8114 - val_accuracy: 0.5906 - val_loss: 0.8601\n",
            "Epoch 56/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6398 - loss: 0.8556 - val_accuracy: 0.6000 - val_loss: 0.8564\n",
            "Epoch 57/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6711 - loss: 0.7891 - val_accuracy: 0.5813 - val_loss: 0.8556\n",
            "Epoch 58/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6503 - loss: 0.8185 - val_accuracy: 0.5938 - val_loss: 0.8520\n",
            "Epoch 59/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6569 - loss: 0.8055 - val_accuracy: 0.6062 - val_loss: 0.8548\n",
            "Epoch 60/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6566 - loss: 0.8057 - val_accuracy: 0.5938 - val_loss: 0.8539\n",
            "Epoch 61/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6496 - loss: 0.7920 - val_accuracy: 0.6062 - val_loss: 0.8613\n",
            "Epoch 62/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6564 - loss: 0.7934 - val_accuracy: 0.6031 - val_loss: 0.8542\n",
            "Epoch 63/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6621 - loss: 0.7773 - val_accuracy: 0.5875 - val_loss: 0.8530\n",
            "Epoch 64/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6871 - loss: 0.7798 - val_accuracy: 0.5938 - val_loss: 0.8535\n",
            "Epoch 65/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6638 - loss: 0.7942 - val_accuracy: 0.6000 - val_loss: 0.8499\n",
            "Epoch 66/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6554 - loss: 0.8159 - val_accuracy: 0.5938 - val_loss: 0.8553\n",
            "Epoch 67/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6875 - loss: 0.7544 - val_accuracy: 0.5938 - val_loss: 0.8533\n",
            "Epoch 68/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6943 - loss: 0.7576 - val_accuracy: 0.6156 - val_loss: 0.8540\n",
            "Epoch 69/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6654 - loss: 0.7822 - val_accuracy: 0.6031 - val_loss: 0.8517\n",
            "Epoch 70/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6603 - loss: 0.7928 - val_accuracy: 0.5969 - val_loss: 0.8524\n",
            "Epoch 71/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6629 - loss: 0.7860 - val_accuracy: 0.6062 - val_loss: 0.8535\n",
            "Epoch 72/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6612 - loss: 0.8020 - val_accuracy: 0.6125 - val_loss: 0.8653\n",
            "Epoch 73/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6581 - loss: 0.8088 - val_accuracy: 0.6031 - val_loss: 0.8604\n",
            "Epoch 74/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6704 - loss: 0.8005 - val_accuracy: 0.6187 - val_loss: 0.8570\n",
            "Epoch 75/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6526 - loss: 0.8047 - val_accuracy: 0.6219 - val_loss: 0.8498\n",
            "Epoch 76/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6913 - loss: 0.7659 - val_accuracy: 0.6156 - val_loss: 0.8454\n",
            "Epoch 77/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7011 - loss: 0.7543 - val_accuracy: 0.6250 - val_loss: 0.8453\n",
            "Epoch 78/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6837 - loss: 0.7745 - val_accuracy: 0.6156 - val_loss: 0.8451\n",
            "Epoch 79/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6821 - loss: 0.7777 - val_accuracy: 0.6219 - val_loss: 0.8475\n",
            "Epoch 80/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6658 - loss: 0.7918 - val_accuracy: 0.6281 - val_loss: 0.8545\n",
            "Epoch 81/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6770 - loss: 0.7629 - val_accuracy: 0.6313 - val_loss: 0.8523\n",
            "Epoch 82/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6717 - loss: 0.7810 - val_accuracy: 0.6187 - val_loss: 0.8486\n",
            "Epoch 83/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6746 - loss: 0.7627 - val_accuracy: 0.6313 - val_loss: 0.8504\n",
            "Epoch 84/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6916 - loss: 0.7378 - val_accuracy: 0.6375 - val_loss: 0.8502\n",
            "Epoch 85/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6707 - loss: 0.7677 - val_accuracy: 0.6156 - val_loss: 0.8517\n",
            "Epoch 86/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6831 - loss: 0.7519 - val_accuracy: 0.6281 - val_loss: 0.8469\n",
            "Epoch 87/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6335 - loss: 0.7855 - val_accuracy: 0.6281 - val_loss: 0.8460\n",
            "Epoch 88/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6857 - loss: 0.7456 - val_accuracy: 0.6313 - val_loss: 0.8485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(X_test, y_test)   # Evaluate the model on test data\n",
        "print(\"Test Accuracy:\", acc)                 # Print the test accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PB9tJFuRJXX",
        "outputId": "061fe275-3583-40d2-849b-ba6c6fcf03fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6265 - loss: 0.8729 \n",
            "Test Accuracy: 0.6156250238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)               # Predict probabilities for each class\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)   # Pick the class with the highest probability\n",
        "y_true_classes = np.argmax(y_test, axis=1)   # Convert one-hot labels back to class numbers\n",
        "\n",
        "print(confusion_matrix(y_true_classes, y_pred_classes))  # Show confusion matrix\n",
        "print(classification_report(y_true_classes, y_pred_classes))  # Print precision, recall, f1-score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Oqa_EqNRSNw",
        "outputId": "08032c7d-9b89-4b1f-bba6-8959086482e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "[[ 0  0  1  0  0  0]\n",
            " [ 0  0  9  1  0  0]\n",
            " [ 0  0 93 36  1  0]\n",
            " [ 0  0 34 87 11  0]\n",
            " [ 0  0  0 25 17  0]\n",
            " [ 0  0  0  1  4  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00        10\n",
            "           2       0.68      0.72      0.70       130\n",
            "           3       0.58      0.66      0.62       132\n",
            "           4       0.52      0.40      0.45        42\n",
            "           5       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.62       320\n",
            "   macro avg       0.30      0.30      0.29       320\n",
            "weighted avg       0.58      0.62      0.60       320\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}